{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MONISH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MONISH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MONISH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt') #for sentence tokenization\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"Artificial intelligence (AI), in its broadest sense,\n",
    "is intelligence exhibited by machines, particularly computer systems. \n",
    "It is a field of research in computer science that develops and studies \n",
    "methods and software that enable machines to perceive their environment\n",
    " and use learning and intelligence to take actions that maximize their chances \n",
    " of achieving defined goals.[1] Such machines may be called AIs.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'intelligence',\n",
       " '(',\n",
       " 'AI',\n",
       " ')',\n",
       " ',',\n",
       " 'in',\n",
       " 'its',\n",
       " 'broadest',\n",
       " 'sense',\n",
       " ',',\n",
       " 'is',\n",
       " 'intelligence',\n",
       " 'exhibited',\n",
       " 'by',\n",
       " 'machines',\n",
       " ',',\n",
       " 'particularly',\n",
       " 'computer',\n",
       " 'systems',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'research',\n",
       " 'in',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'that',\n",
       " 'develops',\n",
       " 'and',\n",
       " 'studies',\n",
       " 'methods',\n",
       " 'and',\n",
       " 'software',\n",
       " 'that',\n",
       " 'enable',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'perceive',\n",
       " 'their',\n",
       " 'environment',\n",
       " 'and',\n",
       " 'use',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'intelligence',\n",
       " 'to',\n",
       " 'take',\n",
       " 'actions',\n",
       " 'that',\n",
       " 'maximize',\n",
       " 'their',\n",
       " 'chances',\n",
       " 'of',\n",
       " 'achieving',\n",
       " 'defined',\n",
       " 'goals',\n",
       " '.',\n",
       " '[',\n",
       " '1',\n",
       " ']',\n",
       " 'Such',\n",
       " 'machines',\n",
       " 'may',\n",
       " 'be',\n",
       " 'called',\n",
       " 'AIs',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(paragraph)\n",
    "words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artifici intellig ( ai ) , broadest sens , intellig exhibit machin , particularli comput system .', 'it field research comput scienc develop studi method softwar enabl machin perceiv environ use learn intellig take action maxim chanc achiev defin goal .', '[ 1 ] such machin may call ai .']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(nltk.corpus.stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words)\n",
    "\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial intelligence ( AI ) , broadest sense , intelligence exhibited machine , particularly computer system .', 'It field research computer science develops study method software enable machine perceive environment use learning intelligence take action maximize chance achieving defined goal .', '[ 1 ] Such machine may called AIs .']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(nltk.corpus.stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words)\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artifici intellig ai broadest sens intellig exhibit machin particularli comput system', 'field research comput scienc develop studi method softwar enabl machin perceiv environ use learn intellig take action maxim chanc achiev defin goal', 'machin may call ai']\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "\n",
    "import re \n",
    "corpus = []\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sent = re.sub('[^a-zA-Z]',' ',sentences[i]) # ^ = not in\n",
    "    sent = sent.lower()\n",
    "    sent = sent.split()\n",
    "    sent = [stemmer.stem(word) for word in sent if not word in set(stopwords.words('english'))] #list comprehension \n",
    "    sent = ' '.join(sent)\n",
    "    corpus.append(sent)\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0,\n",
       "        0, 1, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "        1, 0, 1, 1, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english',lowercase=True,max_features=1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
